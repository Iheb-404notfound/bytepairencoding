{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "166ad7a6-3b96-44bd-b7d8-fbf8e0be749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d194500-7bec-47ed-b1bf-857a06dc9ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BPETokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fd30d7-604e-48a7-b79b-d2e1168482a3",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acb385da-f30f-43b9-b871-75d7534d828a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A serious and good philosophical work could be written consisting entirely of jokes.\n",
      "\n",
      "Wittgenstein\n",
      "The limits of my language means the limits of my world.\n",
      "\n",
      "Wittgenstein\n",
      "I don't know why we are here, but I'm pretty sure that it is not in order to enjoy ourselves.\n",
      "\n",
      "Wittgenstein\n",
      "Whereof one cannot speak, thereof one must be silent.\n",
      "\n",
      "Wittgenstein\n",
      "Hell isn't other people. Hell is yourself.\n",
      "\n",
      "Wittgenstein\n",
      "The real question of life after death isn't whether or not it exists, but even if it does what pro\n"
     ]
    }
   ],
   "source": [
    "with open('quotes.csv') as f:\n",
    "    corpus = f.read().replace('<|>', '\\n\\n')\n",
    "\n",
    "print(corpus[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18d66e3f-6cba-47bf-ac29-19de471ec193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Callem AI\\Experiments\\Own LLM\\Tokenization\\tokenizers\\bpe_tokenizer.py:42\u001b[0m, in \u001b[0;36mBPETokenizer.train\u001b[1;34m(self, corpus, maxvocab, stop_when_anomaly)\u001b[0m\n\u001b[0;32m     39\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[a-zA-Z0-9]+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms[a-zA-Z0-9]+\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabs)\u001b[38;5;241m<\u001b[39mmaxvocab:\n\u001b[1;32m---> 42\u001b[0m     newvocabs, newmerges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_vocabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(pattern, newmerges[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mnewmerges[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m stop_when_anomaly: \u001b[38;5;66;03m#re.match(pattern, newmerges[-1][0]+newmerges[-1][1]):\u001b[39;00m\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTerminalized\u001b[39m\u001b[38;5;124m\"\u001b[39m, newmerges[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\Documents\\Callem AI\\Experiments\\Own LLM\\Tokenization\\tokenizers\\bpe_tokenizer.py:27\u001b[0m, in \u001b[0;36mBPETokenizer._update_vocabs\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     25\u001b[0m vocabs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     26\u001b[0m merges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerges\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 27\u001b[0m occs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_freqs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(occs\u001b[38;5;241m.\u001b[39mkeys(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: occs[x])\n\u001b[0;32m     29\u001b[0m merges\u001b[38;5;241m.\u001b[39mappend(keys)\n",
      "File \u001b[1;32m~\\Documents\\Callem AI\\Experiments\\Own LLM\\Tokenization\\tokenizers\\bpe_tokenizer.py:14\u001b[0m, in \u001b[0;36mBPETokenizer._count_freqs\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count_freqs\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m---> 14\u001b[0m     itext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdivide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     occs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token1, token2 \u001b[38;5;129;01min\u001b[39;00m sliding_window(itext):\n",
      "File \u001b[1;32m~\\Documents\\Callem AI\\Experiments\\Own LLM\\Tokenization\\tokenizers\\bpe_tokenizer.py:55\u001b[0m, in \u001b[0;36mBPETokenizer.divide\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerges:\n\u001b[0;32m     54\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(split) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m split[i]\u001b[38;5;241m==\u001b[39mpair[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m split[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m==\u001b[39mpair[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m     57\u001b[0m             split \u001b[38;5;241m=\u001b[39m split[:i] \u001b[38;5;241m+\u001b[39m [pair[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mpair[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m+\u001b[39m split[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenizer.train(corpus[:10000], 500, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebf42f-57ee-4097-a6a1-fa758d082efd",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb3e9c02-b70e-49e7-84ce-b082650b8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07772ccd-5f1c-40f6-8998-e0ab202b032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=[\"#362A59\", \"#3D6D46\", \"#75592B\", \"#732E31\", \"#235C73\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "098d3097-c48a-466e-b5a2-635a95f359d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"color: white; background: #202123; font-weight: bold; padding: 20px 20px 20px 20px; font-family: 'Courier New', monospace;\">\n",
       "<span style=\"background: #362A59\">\n",
       "</span><span style=\"background: #3D6D46\">th</span><span style=\"background: #75592B\">is </span><span style=\"background: #732E31\">is the </span><span style=\"background: #235C73\">h</span><span style=\"background: #362A59\">u</span><span style=\"background: #3D6D46\">g</span><span style=\"background: #75592B\">g</span><span style=\"background: #732E31\">ing </span><span style=\"background: #235C73\">f</span><span style=\"background: #362A59\">a</span><span style=\"background: #3D6D46\">ce </span><span style=\"background: #75592B\">c</span><span style=\"background: #732E31\">ou</span><span style=\"background: #235C73\">r</span><span style=\"background: #362A59\">se</span><span style=\"background: #3D6D46\">,</span><span style=\"background: #75592B\"> th</span><span style=\"background: #732E31\">is </span><span style=\"background: #235C73\">ch</span><span style=\"background: #362A59\">a</span><span style=\"background: #3D6D46\">p</span><span style=\"background: #75592B\">t</span><span style=\"background: #732E31\">er </span><span style=\"background: #235C73\">is </span><span style=\"background: #362A59\">ab</span><span style=\"background: #3D6D46\">ou</span><span style=\"background: #75592B\">t</span><span style=\"background: #732E31\"> to</span><span style=\"background: #235C73\">k</span><span style=\"background: #362A59\">en</span><span style=\"background: #3D6D46\">i</span><span style=\"background: #75592B\">z</span><span style=\"background: #732E31\">ation</span><span style=\"background: #235C73\">.</span><span style=\"background: #362A59\"> th</span><span style=\"background: #3D6D46\">is </span><span style=\"background: #75592B\">se</span><span style=\"background: #732E31\">c</span><span style=\"background: #235C73\">t</span><span style=\"background: #362A59\">ion</span><span style=\"background: #3D6D46\"> </span><span style=\"background: #75592B\">sh</span><span style=\"background: #732E31\">ow</span><span style=\"background: #235C73\">s </span><span style=\"background: #362A59\">s</span><span style=\"background: #3D6D46\">ev</span><span style=\"background: #75592B\">er</span><span style=\"background: #732E31\">al</span><span style=\"background: #235C73\"> to</span><span style=\"background: #362A59\">k</span><span style=\"background: #3D6D46\">en</span><span style=\"background: #75592B\">i</span><span style=\"background: #732E31\">z</span><span style=\"background: #235C73\">er </span><span style=\"background: #362A59\">al</span><span style=\"background: #3D6D46\">g</span><span style=\"background: #75592B\">or</span><span style=\"background: #732E31\">ith</span><span style=\"background: #235C73\">m</span><span style=\"background: #362A59\">s</span><span style=\"background: #3D6D46\">. </span><span style=\"background: #75592B\">\n",
       "</span><span style=\"background: #732E31\">h</span><span style=\"background: #235C73\">u</span><span style=\"background: #362A59\">g</span><span style=\"background: #3D6D46\">g</span><span style=\"background: #75592B\">ing</span><span style=\"background: #732E31\">f</span><span style=\"background: #235C73\">a</span><span style=\"background: #362A59\">ce </span><span style=\"background: #3D6D46\">is </span><span style=\"background: #75592B\">le</span><span style=\"background: #732E31\">ar</span><span style=\"background: #235C73\">n</span><span style=\"background: #362A59\">ing </span><span style=\"background: #3D6D46\">n</span><span style=\"background: #75592B\">e</span><span style=\"background: #732E31\">w</span><span style=\"background: #235C73\"> </span><span style=\"background: #362A59\">a</span><span style=\"background: #3D6D46\">st</span><span style=\"background: #75592B\">on</span><span style=\"background: #732E31\">is</span><span style=\"background: #235C73\">h</span><span style=\"background: #362A59\">ing </span><span style=\"background: #3D6D46\">and </span><span style=\"background: #75592B\">b</span><span style=\"background: #732E31\">r</span><span style=\"background: #235C73\">il</span><span style=\"background: #362A59\">li</span><span style=\"background: #3D6D46\">ant</span><span style=\"background: #75592B\"> t</span><span style=\"background: #732E31\">e</span><span style=\"background: #235C73\">ch</span><span style=\"background: #362A59\">n</span><span style=\"background: #3D6D46\">i</span><span style=\"background: #75592B\">qu</span><span style=\"background: #732E31\">es</span><span style=\"background: #235C73\"> that </span><span style=\"background: #362A59\">are </span><span style=\"background: #3D6D46\">s</span><span style=\"background: #75592B\">up</span><span style=\"background: #732E31\">er</span><span style=\"background: #235C73\">p</span><span style=\"background: #362A59\">el</span><span style=\"background: #3D6D46\">l</span><span style=\"background: #75592B\">ant</span><span style=\"background: #732E31\">. </span><span style=\"background: #235C73\">\n",
       "</span><span style=\"background: #362A59\">I</span><span style=\"background: #3D6D46\">'</span><span style=\"background: #75592B\">m </span><span style=\"background: #732E31\">happ</span><span style=\"background: #235C73\">y</span><span style=\"background: #362A59\">ly </span><span style=\"background: #3D6D46\">j</span><span style=\"background: #75592B\">o</span><span style=\"background: #732E31\">in</span><span style=\"background: #235C73\">ing</span><span style=\"background: #362A59\"> the </span><span style=\"background: #3D6D46\">wor</span><span style=\"background: #75592B\">ld </span><span style=\"background: #732E31\">of </span><span style=\"background: #235C73\">a</span><span style=\"background: #362A59\">i</span><span style=\"background: #3D6D46\"> </span><span style=\"background: #75592B\">as </span><span style=\"background: #732E31\">it </span><span style=\"background: #235C73\">is </span><span style=\"background: #362A59\">m</span><span style=\"background: #3D6D46\">o</span><span style=\"background: #75592B\">v</span><span style=\"background: #732E31\">ing </span><span style=\"background: #235C73\">for</span><span style=\"background: #362A59\">w</span><span style=\"background: #3D6D46\">ar</span><span style=\"background: #75592B\">d</span><span style=\"background: #732E31\">. </span><span style=\"background: #235C73\">\n",
       "</span><span style=\"background: #362A59\">I </span><span style=\"background: #3D6D46\">j</span><span style=\"background: #75592B\">o</span><span style=\"background: #732E31\">y</span><span style=\"background: #235C73\">f</span><span style=\"background: #362A59\">o</span><span style=\"background: #3D6D46\">l</span><span style=\"background: #75592B\">ly </span><span style=\"background: #732E31\">and </span><span style=\"background: #235C73\">gre</span><span style=\"background: #362A59\">at</span><span style=\"background: #3D6D46\">f</span><span style=\"background: #75592B\">ul</span><span style=\"background: #732E31\">l</span><span style=\"background: #235C73\">y</span><span style=\"background: #362A59\"> t</span><span style=\"background: #3D6D46\">r</span><span style=\"background: #75592B\">y</span><span style=\"background: #732E31\">ing</span><span style=\"background: #235C73\"> to </span><span style=\"background: #362A59\">g</span><span style=\"background: #3D6D46\">et</span><span style=\"background: #75592B\"> th</span><span style=\"background: #732E31\">is </span><span style=\"background: #235C73\">don</span><span style=\"background: #362A59\">e</span><span style=\"background: #3D6D46\">. </span><span style=\"background: #75592B\">h</span><span style=\"background: #732E31\">u</span><span style=\"background: #235C73\">g</span><span style=\"background: #362A59\">g</span><span style=\"background: #3D6D46\">ing</span><span style=\"background: #75592B\">f</span><span style=\"background: #732E31\">a</span><span style=\"background: #235C73\">ce </span><span style=\"background: #362A59\">h</span><span style=\"background: #3D6D46\">u</span><span style=\"background: #75592B\">g</span><span style=\"background: #732E31\"> </span><span style=\"background: #235C73\">f</span><span style=\"background: #362A59\">a</span><span style=\"background: #3D6D46\">ce </span><span style=\"background: #75592B\">h</span><span style=\"background: #732E31\">u</span><span style=\"background: #235C73\">g</span><span style=\"background: #362A59\">g</span><span style=\"background: #3D6D46\">ing </span><span style=\"background: #75592B\">h</span><span style=\"background: #732E31\">u</span><span style=\"background: #235C73\">g</span><span style=\"background: #362A59\">g</span><span style=\"background: #3D6D46\">er </span><span style=\"background: #75592B\">le</span><span style=\"background: #732E31\">ar</span><span style=\"background: #235C73\">n</span><span style=\"background: #362A59\">ing </span><span style=\"background: #3D6D46\">le</span><span style=\"background: #75592B\">ar</span><span style=\"background: #732E31\">n</span><span style=\"background: #235C73\">er </span><span style=\"background: #362A59\">le</span><span style=\"background: #3D6D46\">ar</span><span style=\"background: #75592B\">n</span><span style=\"background: #732E31\">er</span><span style=\"background: #235C73\">s </span><span style=\"background: #362A59\">le</span><span style=\"background: #3D6D46\">ar</span><span style=\"background: #75592B\">n </span><span style=\"background: #732E31\">1</span><span style=\"background: #235C73\">2</span><span style=\"background: #362A59\">3</span><span style=\"background: #3D6D46\">\n",
       "</span>\n",
       "</div>\n",
       "\n",
       "```python\n",
       "result = [21, 189, 99, 284, 31, 32, 54, 54, 128, 38, 19, 227, 50, 69, 33, 336, 43, 63, 99, 80, 19, 24, 5, 122, 99, 195, 69, 5, 193, 12, 65, 36, 40, 192, 56, 63, 99, 336, 50, 5, 133, 25, 328, 155, 62, 42, 131, 64, 78, 193, 12, 65, 36, 40, 122, 78, 54, 88, 191, 35, 42, 93, 21, 31, 32, 54, 54, 85, 38, 19, 227, 99, 164, 87, 48, 128, 48, 51, 7, 25, 19, 74, 70, 102, 31, 128, 148, 30, 33, 132, 89, 342, 59, 51, 80, 48, 36, 212, 91, 159, 188, 42, 220, 64, 24, 79, 13, 342, 93, 21, 45, 27, 210, 291, 34, 173, 0, 49, 61, 85, 76, 237, 160, 86, 19, 36, 25, 243, 146, 99, 35, 49, 22, 128, 154, 7, 87, 20, 93, 21, 130, 0, 49, 34, 38, 49, 13, 173, 148, 319, 100, 38, 309, 13, 34, 59, 33, 34, 85, 83, 54, 82, 63, 99, 238, 51, 93, 31, 32, 54, 54, 85, 38, 19, 227, 31, 32, 54, 25, 38, 19, 227, 31, 32, 54, 54, 128, 31, 32, 54, 54, 122, 164, 87, 48, 128, 164, 87, 48, 122, 164, 87, 48, 64, 62, 164, 87, 207, 21]\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "this is the hugging face course, this chapter is about tokenization. this section shows several tokenizer algorithms. \n",
    "huggingface is learning new astonishing and brilliant techniques that are superpellant. \n",
    "I'm happyly joining the world of ai as it is moving forward. \n",
    "I joyfolly and greatfully trying to get this done. huggingface hug face hugging hugger learning learner learners learn 123\n",
    "\"\"\"\n",
    "tokenized = tokenizer.divide(text)\n",
    "mark = \"\"\n",
    "for i, token in enumerate(tokenized):\n",
    "    mark+=f'''<span style=\"background: {colors[i%len(colors)]}\">{token}</span>'''\n",
    "Markdown(f'''<div style=\"color: white; background: #202123; font-weight: bold; padding: 20px 20px 20px 20px; font-family: 'Courier New', monospace;\">\n",
    "{mark}\n",
    "</div>\n",
    "\n",
    "```python\n",
    "result = {tokenizer.encode(text)}\n",
    "```\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87a4d5a6-5df7-4a14-8be0-86478793d58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nthis is the hugging face course, this chapter is about tokenization. this section shows several tokenizer algorithms.\\nhuggingface is learning new astonishing and brilliant techniques that are superpellant. I'm happyly joining the world of ai\\nas it is moving forward. I joyfolly and greatfully trying to get this done.\\nhuggingface hug face hugging hugger learning learner learners learn \\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text+\"123123\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d5ae62-5f77-4c0a-80d5-2aeaf2de0112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
